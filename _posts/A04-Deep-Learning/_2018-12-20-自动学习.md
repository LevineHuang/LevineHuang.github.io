---
typora-root-url: ../../../LevineHuang.github.io
---

# AutoML自动机器学习平台

当前：

$Solution = ML Expertise + Data + Computing Power$

未来：

$Solution = Data + Computing Power * 100$



## AutoML背景

机器学习(Machine Learning, ML)技术近年来已取得较大成功，越来越多行业领域依赖它。但目前成功的关键还需依赖人类机器学习工程师完成以下工作：

- 预处理数据
- 特征工程：包括特征选择、特征降维、特征生成、以及特征编码等
- 模型选择：包括算法选择、模型结构设计、超参数优化等
- 优化算法选择
- 模型评估

目前，世界上只有小部分企业拥有足够的人力财力资源充分发挥AI和机器学习的潜能，也只有小部分人有能力开发出先进的机器学习模型。但即使这样一小部分拥有AI专家的企业，也仍需大量时间且反复过程才能构建出自定义的机器学习系统。

AutoML 试图将这些与特征、模型、优化、评价有关的重要步骤进行自动化地学习，使得机器学习模型无需人工干预即可被应用。

![](/assets/imgs/A04/1545393309467.png)

<center>AotoML如何最小化机器学习pipeline中人工干预 (Quanming Yao et al, 2018)<center/>

## AutoML定义

从名字来看，AutoML是自动化与机器学习的交叉。

#### 定义

1. 从机器学习角度讲，AutoML 可以看作是一个在给定数据和任务上学习泛化能力非常强大的系统。但是它强调必须非常容易使用；

2. 从自动化角度讲，AutoML 则可以看作是设计一系列高级的控制系统去操作机器学习模型，使得模型可以自动化地学习到合适的参数和配置而无需人工干预。 

从上述定义可以看出，AutoML不仅期望学习的模型具有良好的学习性能，而且要求自动化地学习到合适的参数和配置而无需人工干预。一个通用的 AutoML 定义如下：
$$
\begin{equation}
\max_{configurations}\text{performance of learning tools,} \\
s.t. \begin{cases}
\text {no human assistance} \\
\text {limited computational budget}
\end{cases}
\end{equation}
$$
即在无人工干预和有限计算资源预算的约束下，学习到一组能够最大化模型性能的模型参数配置(configurations)。这里，**模型参数配置(configurations)指影响模型性能的几乎所有的因素，比如：模型的假设类型，模型利用的特征，控制模型训练过程的超参数，网络架构等**。

#### AutoML的核心任务

- 更好地性能：在不同的输入数据和学习任务上有良好的泛化能力
- 无需人工干预
- 更低的计算开销

## AutoML方法框架

框架的作用：通过对某一主题相关的知识进行系统的梳理，对现有的研究方法进行分类，总结当前存在的问题，并指导新方法的设计。

一个基本的AutoML框架如下图所示，controller模块取代机器学习专家的位置为模型找到合适的参数配置。controller包含两个关键的部分：Optimizer和Evaluator。

机器学习过程中的特征、模型算法决定了Optimizer的搜索空间，Optimizer在参数搜索空间中搜索一组合适的模型参数配置。

Evaluator对给定的参数配置进行性能评估，通常需要用搜索到的参数配置在输入数据上进行模型训练进行评估，或结合人的经验直接进行评估。Evaluator生成反馈给Optimizer(非必须，依赖于所选择优化算法的类型)。

然后Optimizer更新新的模型参数配置。

![](/assets/imgs/A04/image-20190113172700970.png)

<center>AutoML基本框架<center/>

## AutoML方法分类

将什么自动化

如何进行自动化

## AutoML问题构成



## AutoML技术原理

### 自动特征工程

Deep Feature Synthesis (DFS)：自动生成特征，表达丰富的特征空间。

通过DFS算法生成特征，并自动调优一个机器学习路径从合成的特征中提取最有价值的特征。



### 自动超参数优化

近期对具有大量超参数的复杂的、计算开销极大的机器学习模型的兴趣引发了大家对超参数优化(hyperparameter optimization, HPO)的研究。

#### 超参数优化方法

超参数优化方法包括：

- 基于model-free方法的黑箱函数优化方法。
- 贝叶斯优化方法。
- modern multi-fidelity methods，使用比黑箱函数方法更轻量级的方法，近似地对超参数设置的质量进行评估，降低计算开销。

#### 自动超参数优化的意义

自动超参数优化具有重要意义：

- 降低应用机器学习是人类投入的必要性。这在AutoML环境中尤为重要。
- 提高机器学习算法的性能。在多项研究中，自动超参数优化已经使得模型取得了新的SOTA性能表现。
- 提高科学研究的可重复性和公平性。自动超参数优化比人工调参更容易复现结果，也方便对同一问题不容的方法进行公平的比较。

#### 自动超参数优化的价值

由于使用机器学习的公司不断增加，超参数优化的商业价值也逐渐凸显，起到更大的作用，例如：

- 作为公司内部的工具。
- 作为机器学习云服务的一部分。
- 单独作为一项服务。

#### 自动超参数优化面临的挑战

- 

### 网络架构搜索

#### 问题定义

**网络架构和超参数优化的问题，有以下的特点：** 

1. 评价函数未知，是一个黑箱优化问题，因为评价往往是在 unseen dataset 上进行评价；

2. 非线性；

3. 非凸；

4. 混合优化，既有离散空间，又有连续空间； 

5. 一次优化结果的评价非常耗时，大型的深度学习模型参数数以亿计，运行一次结果需要几周时间；

6. 在某些应用场景中，存在多个目标。比如：移动端的模型结构优化，既希望得到尽量高的准确率，又希望有非常好的模型计算效率。

#### 搜索空间

#### 搜索策略

**搜索策略定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置。**常见的搜索方法包括：Grid search（网格搜索）、Random search（随机搜索）、Genetic algorithm（遗传算法）、Paticle Swarm Optimization（粒子群优化）、Bayesian Optimization（贝叶斯优化）、TPE、SMAC、基于梯度的方法、强化学习、迁移学习等。

##### 进化算法

进化算法是一大类算法，大概的框架也基本类似，先随机生成一个种群（N 组解），开始循环以下几个步骤：选择、交叉、变异，直到满足最终条件。在基于 EA 的方法中，搜索是通过架构组件的变异和再组合来进行的，性能更优的架构会被筛选出来继续进化。

最近几年流行一种基于概率模型的进化算法 EDA (Estimation Distribution of Algorithm)，基本的思路类似遗传算法，不同的是没有交叉、变异的环节，而是通过 learning 得到一个概率模型，由概率模型来 sample 下一步的种群。 

近两年几家高科技企业做 NAS 时都在用进化算法优化网络结构，同时用基于梯度的方法（BP）来优化权值。在 NAS 任务中，进化算法的交叉算子和任务结合比较紧，被定义为一些类似添加、删除层的操作，而非简单的更改某一位编码。 用进化算法解决 NAS 问题，不同的工作可能聚焦在不同的过程中，比如如何 sample 种群，如何 update 种群，如何生成子代种群等。

**进化算法是一种无梯度的优化算法（Derivative Free Optimization Algorithm），优点是可能会得到全局最优解，缺点是效率相对较低**。90 年代的学者用进化算法同时优化网络结构参数和各层之间的权重，因为当时的网络规模非常小，所以还能解决，但后续深度学习模型网络规模都非常大，无法直接优化。 

##### 贝叶斯优化

一种基于模型的用于寻找函数最小值的方法。是超参数优化问题的常用手段，尤其是针对一些低维的问题，基于高斯过程（Gaussian Processes）和核方法（kernel trick）。对于高维优化问题，一些工作融合了树模型或者随机森林来解决，取得了不错的效果。除了常见的三大类方法，一些工作也在研究分层优化的思路，比如将进化算法和基于模型的序列优化方法融合起来，取各种方法的优势。

-  高斯过程
- 随机森林
- 树模型

##### 强化学习

强化学习是一种非常有意思的范式，几乎只要可以提炼出强化学习四要素，原问题就可以用强化学习来求解。 

在 NAS 任务中，将架构的生成看成是一个 agent 在选择 action，一系列动作定义了神经网络的架构，reward 是通过一个测试集上的效果预测函数来获得（这个函数类似于工程优化问题中的 surrogate model，即代理模型）。因为在 NAS 任务中，agent 与环境没有交互，可以降阶为无状态的多臂老虎机（MAB）问题。 **这类工作整体的框架都是基于此，不同的点在于策略函数和优化算法。** 

一个工作是，用 RNN 来表示策略函数，初始化时先用策略梯度算法赋初值，然后用 PPO 来进行优化。另一个工作是，用简单的 Q-learning 算法来训练策略函数，序列地进行动作选择，即选择 layer 的类型和相关的超参数。

##### 连续空间神经架构优化(NAO)

基于 RL 和 EA 的方法本质上都是在离散的架构空间中执行搜索。因为神经网络架构的选择通常都是离散的，例如 CNN 中的滤波器大小还有 RNN 单元中的连接拓扑（connection topology）。然而，在离散空间中直接搜索最优架构是很低效的，因为随着选择的增加，搜索空间会呈指数增长。

微软&中科大提出新型自动神经架构设计方法**NAO**(**Neural Architecture Optimization**)，将架构映射到一个连续的向量空间（即网络嵌入），利用基于梯度的方法在该连续空间进行优化。一方面，与自然语言的分布式表示类似，架构的连续表示在表示拓扑信息时更加紧凑和有效； 另一方面，由于更加平滑，在连续空间中进行优化比在离散空间内直接搜索容易得多。

**原理**

简言之，NAO包含三个关键部分：

- 编码器，将神经网络架构嵌入/映射到连续空间；
- 预测器，将网络的连续表示作为输入，并预测其准确率；
- 解码器，将网络的连续表示映射回其架构。性能预测器和编码器使我们能够在连续空间中执行基于梯度的优化，以找到潜在的准确率更高的新架构嵌入。然后将这个更优的嵌入使用解码器解码到网络。

具体如下图所示，编码器将神经网络架构嵌入/映射到连续空间(左侧蓝色箭头)，在连续空间上建立一个回归模型来逼近架构的最终性能(黄色部分)，回归模型类似于之前研究中的性能预测器 。新方法与之的区别在于如何利用性能预测器：之前的研究使用性能预测器作为启发来选择已生成的架构，以加速搜索过程，而新方法直接优化模块，并通过梯度下降获得更好网络的连续表示(中间底部黑色箭头)。然后利用优化的表示来产生预测性能更好的新神经网络架构。为了实现这一点，NAO 的另一个关键模块被设计成解码器，从连续表示中恢复离散架构（右侧红框箭头）。解码器是配备了注意力机制的 LSTM 模型，可以实现精准恢复。这三个组件（即编码器、性能预测器和解码器）在多任务设置中接受联合训练，这有利于连续表示：恢复架构的解码器目标能进一步改善架构嵌入的质量，更有效地预测性能。

![img](https://ws2.sinaimg.cn/large/006tNc79ly1fyvquwq269j30la09i41w.jpg)

**表现**

NAO所发现的架构在 CIFAR-10 上的图像分类任务和 PTB 上的语言建模任务中都表现强劲，在计算资源明显减少的情况下都优于或持平于之前的架构搜索最佳方法。其中 CIFAR-10 图像分类任务的测试集误差率为 2.07%，PTB 语言建模任务的测试集困惑度为 55.9。在两个任务中发现的最优架构可被成功迁移到其他任务，如 CIFAR-100 和 WikiText-2。

##### 可微分网络结构搜索（DARTS）

由卡内基梅隆大学和 DeepMind 的一个团队发布。

假设候选架构的空间是连续的，而不是离散的，这样它就能够使用基于梯度的方式，它的效率比大多数神经架构搜索算法使用的低效黑盒搜索要高得多。

要点是如何将一个网络可微化。 可微意味着网络结构能够利用梯度下降法进行训练。神经网络模型是一个复合函数，想要让模型本身可微分，就得需要将模型表示成函数的函数，这就是高阶函数。在训练过程中不仅学习函数的参数，还要学习高阶函数的参数。高阶函数的参数描述了函数的结构，权重描述了函数本身。

**原理**

Cell 是一个有向图，每个点表示一个神经元，每个边表示神经网络的运算符。在训练之前每条边的真实运算符未知。例如在卷积神经网络中，神经元之间可能是`Conv2D`, `Relu`, `Pooling`等等。 每条边的不同选择都能得到不同的神经网络结构。 如果暴力搜索的话，搜索空间将非常巨大！

![img](http://sjzcv.com/images/overview-of-DARTS.png)

该方法巧妙的地方在于， 将这种非此即彼的操作符选择进行松弛化为`Softmax`加权组合。于是每条边的操作符可以表达成：

[![img](http://sjzcv.com/images/cell-operator.png)](http://sjzcv.com/images/cell-operator.png)

训练网络的时候不仅要训练每个操作符本身的权重，还要训练其对应的`Softmax`参数：α. α 就是我们的高阶函数的参数。当α确定之后，我们的网络结构也即确定了。



#### 性能预估策略

性能预估类似于工程优化中的代理模型（surrogate model），因为深度学习模型的效果非常依赖于训练数据的规模，大规模数据上的模型训练会非常耗时，对优化结果的评价将会非常耗时，所以需要一些手段去做近似的评估。

##### 低保真策略

低保真在实际应用有多种表达：

- 训练更少的次数
- 用原始训练数据的一部分
- 低分辨率的图片
- 每一层用更少的滤波器等

用这种低保真的训练集来测试优化算法会大大降低计算时间，但也存在一定的 bias，不过选择最优的架构并不需要绝对数值，只需要有相对值就可以进行排序选优了。 

##### 回归策略

用观测到的点进行插值预测，这类方法中最重要的是在大搜索空间中如何选择尽量少的点预测出最优结果的位置。 

##### 参数迁移策略

用之前已经训练好的模型权重参数对target问题进行赋值，从一个高起点的初值开始寻优将会大大地提高效率。

##### One-Shot架构搜索策略

将所有架构视作一个 one-shot 模型（超图）的子图，子图之间通过超图的边来共享权重。

#### NAS的未来研究方法

- 研究针对多任务和多目标问题的 NAS； 
- 研究更加灵活的搜索变量表示，类似 cell 这种方便进行迁移的表示方式； 
- 挖掘更多的、有难度的 benchmark； 
- 迁移学习的引入，进一步提高效率。

### 多目标AutoML



### 基本优化策略

### 基本评价策略

### 高级评价策略

#### **Meta-learning 法**

从先前的学习经验中提炼出基本的参数和结构配置。

先前的学习经验如何刻画？

如何决定提取哪些经验？

如何运用到新的任务中？****

#### **Transfer learning 法**

从先前的学习经验中提炼出可以重用的一些知识

## AutoML 系统

### Data Science Machine(DSM)

### ExploreKit

### FeatureHub

### FeatureLab

### FeatureTools

是一个基于Deep Feature Synthesis (DFS)对结构化数据集(关系型数据和时间序列数据)进行自动特征工程的python库。

#### 基本概念

##### EntitySet

实体及实体之间关系的集合。

##### Feature Primitives

DFS这个名字来自于算法堆叠原语(primitive)以生成更复杂的特征。每次增加原语时，会增加特征的“深度”。

- Aggression primitive 
- Transform primitive 



### Auto-WEKA

Auto-WEKA是最早的一个AutoML库，于2013年首次发布，用于自动模型选择和超参数选择。

### Hyperopt-Sklearn

### Auto-sklearn

将Auto-WEK扩展至python。

进行机器学习算法的自动选择与超参数的自动优化，使用的技术包括贝叶斯优化、元学习和模型集成（ensemble construction）。

### Auto-Net

### ML4AAD

Machine Learning for Automated Algorithm Design

### Automatic Statistician

### Auto-Keras

H2O AutoML（<http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html>）

使用强化学习进行 Neural Architecture Search



## AutoML产品、平台

### [Cloud AutoML](https://cloud.google.com/automl/)

#### 产品介绍

让机器学习知识有限的企业或个人用户利用 Google 最先进的迁移学习技术以及神经架构搜索技术，针对其业务需求训练出高品质模型。另一方面，Cloud AutoML能使AI专家们更加高效，帮助其构建更强大AI系统的同时，帮助其拓展新的领域。

目前支持一下领域的自动机器学习：

- AutoML 视觉

- AutoML 自然语言

- AutoML 翻译

![img](/assets/imgs/A04/autoML-1.png)

![img](/assets/imgs/A04/8cfc7bcbd6b94aed8f7f05b06d49d5d4.gif)

#### 核心原理

AutoML由控制器(Controller)和子网络(Child)两个神经网络组成，控制器生成子模型架构，子模型架构执行特定的任务训练并评估模型的优劣反馈给控制器，控制器将会将此结果作为下一个循环修改的参考。重复执行数千次“设计新架构、评估、回馈、学习”的循环后，控制器能设计出最准确的模型架构。

![img](/assets/imgs/A04/autoML-2.png)

#### 技术基础

##### Transfer Learning 技术

谷歌通过迁移学习（Transfer Learning）将已训练完成的模型，转移到新的模型训练过程。这样，能够用较少量数据训练出机器学习模型。虽然只拥有很少的数据，但谷歌用友很多类似的AI模型，所以通过迁移学习，谷歌可以将这两者结合起来，生成一个满足需求的AI模型。

##### Learning2Learn 技术

自动挑选适合的模型

##### Hyperparameter tuning 技术

自动调整参数

##### Neural Architecture Search技术

AutoML用的是增强学习（迭代）+RNN生成的方法，实际上针对的是CNN的网络结构，用深度学习调参来训练确定网络构架。

### 亚马逊

https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html

### SIGOPT

https://sigopt.com/

### 阿里PAI AutoML Engine



### 华为 Model Arts

#### 图像分类

识别一张图片中是否包含某种物体

#### 物体检测

识别出图片中每个物体的位置及类别

#### 预测分析

对结构化数据做出分类或数值预测

##### 

数据预览，用户界面选择label和feature列，以及模型类型(分类、回归)，自动训练好模型，并输出在验证集上的模型评估结果。发布模型，部署上线。

## 自动机器学习平台设计

自动建模

自动模型更新

部署上线，资源自动弹性伸缩

## AutoML未来研究方向

- 提高AutoML的效率
- 更明确的问题定义
- 发展基本和高级的搜索策略
- 找到更适合的应用



#### 自动化特征工程

定义：从一组相关的数据表中自动提取有用且有意义的特征

**ExploreKit**

**Featuretools**



https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/82392735

优势

- 缩减人工特征工程时间成本，生成更有意义的特征，构建更优秀的预测模型

- 防止数据泄漏(data leakage)

原理

https://new.qq.com/omn/20181026/20181026A0SOXP.html

深度特征合成方法（DFS）

特征基元（feature primitives）

IV

![](/assets/imgs/A04/feature_tools_fi)

<center>利用Featuretools，随机森林模型所获取的15个最重要特征<center/>

#### 自动模型结构设计、优化，神经网络架构搜索（NAS）、模型选择

https://www.jqr.com/article/000356



#### 自动超参数调优



AutoML领域关注的核心问题

- 如何让模型选择和超参数优化自动化？

- 人类如何与计算机合作，从而让机器学习更有效呢？

  增强机器学习是关注如何让人与机器更好合作的话题，其中一个案例是Leslie Smith的*leaning rate finder*这篇论文，其中提到学习率是一个可以决定模型训练速度的超参数，或者可以决定模型能否成功训练。学习速率查询器可以让人类很容易地找到一个良好的学习率，比AutoML更快。



参考文献

https://www.automl.org/automl/literature-on-neural-architecture-search/